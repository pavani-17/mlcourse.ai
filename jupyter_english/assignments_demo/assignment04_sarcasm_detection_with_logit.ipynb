{"cells":[{"cell_type":"markdown","source":"<center>\n<img src=\"../../img/ods_stickers.jpg\">\n    \n## [mlcourse.ai](https://mlcourse.ai) - Open Machine Learning Course\n\nAuthor: [Yury Kashnitsky](https://www.linkedin.com/in/festline/). All content is distributed under the [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license.","metadata":{"_uuid":"3f6c2bfe6b2e26c92357e896a1511195d836956e","cell_id":"1d1b29d2-4d02-4a31-beaf-3a51905df508"}},{"cell_type":"markdown","source":"## <center> Assignment 4 (demo)\n### <center>  Sarcasm detection with logistic regression\n    \n**Same assignment as a [Kaggle Kernel](https://www.kaggle.com/kashnitsky/a4-demo-sarcasm-detection-with-logit) + [solution](https://www.kaggle.com/kashnitsky/a4-demo-sarcasm-detection-with-logit-solution).**\n\n\nWe'll be using the dataset from the [paper](https://arxiv.org/abs/1704.05579) \"A Large Self-Annotated Corpus for Sarcasm\" with >1mln comments from Reddit, labeled as either sarcastic or not. A processed version can be found on Kaggle in a form of a [Kaggle Dataset](https://www.kaggle.com/danofer/sarcasm).\n\nSarcasm detection is easy. \n<img src=\"https://habrastorage.org/webt/1f/0d/ta/1f0dtavsd14ncf17gbsy1cvoga4.jpeg\" />","metadata":{"_uuid":"cb01ca96934e5c83a36a2308da9645b87a9c52a0","cell_id":"9f1b5b23-94b2-490b-bbd0-ab56b862c386"}},{"cell_type":"code","metadata":{"_uuid":"23a833b42b3c214b5191dfdc2482f2f901118247","cell_id":"e4129c4d-8163-4f14-9d2d-4ed418f3e4cc"},"source":"!ls ../input/sarcasm/","outputs":[{"name":"stdout","output_type":"stream","text":"test-balanced.csv  test-unbalanced.csv\ttrain-balanced-sarcasm.csv\r\n"}],"execution_count":null},{"cell_type":"code","metadata":{"_uuid":"ffa03aec57ab6150f9bec0fa56cd3a5791a3e6f4","cell_id":"9547da35-b497-4e36-af3f-6638454d1a73"},"source":"# some necessary imports\nimport os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport seaborn as sns\nfrom matplotlib import pyplot as plt","outputs":[],"execution_count":null},{"cell_type":"code","metadata":{"_uuid":"b23e4fc7a1973d60e0c6da8bd60f3d921542a856","cell_id":"f53400bf-ff06-4743-9c49-879e55adfd84"},"source":"train_df = pd.read_csv('../input/sarcasm/train-balanced-sarcasm.csv')","outputs":[],"execution_count":null},{"cell_type":"code","metadata":{"_uuid":"4dc7b3787afa46c7eb0d0e33b0c41ab9821c4a27","cell_id":"0ed57462-8046-44c0-9edc-6df5fb7b2e24"},"source":"train_df.head()","outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>comment</th>\n      <th>author</th>\n      <th>subreddit</th>\n      <th>score</th>\n      <th>ups</th>\n      <th>downs</th>\n      <th>date</th>\n      <th>created_utc</th>\n      <th>parent_comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NC and NH.</td>\n      <td>Trumpbart</td>\n      <td>politics</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2016-10</td>\n      <td>2016-10-16 23:55:23</td>\n      <td>Yeah, I get that argument. At this point, I'd ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>You do know west teams play against west teams...</td>\n      <td>Shbshb906</td>\n      <td>nba</td>\n      <td>-4</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2016-11</td>\n      <td>2016-11-01 00:24:10</td>\n      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>They were underdogs earlier today, but since G...</td>\n      <td>Creepeth</td>\n      <td>nfl</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2016-09</td>\n      <td>2016-09-22 21:45:37</td>\n      <td>They're favored to win.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>This meme isn't funny none of the \"new york ni...</td>\n      <td>icebrotha</td>\n      <td>BlackPeopleTwitter</td>\n      <td>-8</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2016-10</td>\n      <td>2016-10-18 21:03:47</td>\n      <td>deadass don't kill my buzz</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>I could use one of those tools.</td>\n      <td>cush2push</td>\n      <td>MaddenUltimateTeam</td>\n      <td>6</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2016-12</td>\n      <td>2016-12-30 17:00:13</td>\n      <td>Yep can confirm I saw the tool they use for th...</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"   label                        ...                                                             parent_comment\n0      0                        ...                          Yeah, I get that argument. At this point, I'd ...\n1      0                        ...                          The blazers and Mavericks (The wests 5 and 6 s...\n2      0                        ...                                                    They're favored to win.\n3      0                        ...                                                 deadass don't kill my buzz\n4      0                        ...                          Yep can confirm I saw the tool they use for th...\n\n[5 rows x 10 columns]"},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"execution_count":null},{"cell_type":"code","metadata":{"_uuid":"0a7ed9557943806c6813ad59c3d5ebdb403ffd78","cell_id":"969898c6-75a6-4d4a-9daf-5c553cf6d380"},"source":"train_df.info()","outputs":[{"name":"stdout","output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1010826 entries, 0 to 1010825\nData columns (total 10 columns):\nlabel             1010826 non-null int64\ncomment           1010773 non-null object\nauthor            1010826 non-null object\nsubreddit         1010826 non-null object\nscore             1010826 non-null int64\nups               1010826 non-null int64\ndowns             1010826 non-null int64\ndate              1010826 non-null object\ncreated_utc       1010826 non-null object\nparent_comment    1010826 non-null object\ndtypes: int64(4), object(6)\nmemory usage: 77.1+ MB\n"}],"execution_count":null},{"cell_type":"markdown","source":"Some comments are missing, so we drop the corresponding rows.","metadata":{"_uuid":"6472f52fb5ecb8bb2a6e3b292678a2042fcfe34c","cell_id":"2a8aa663-e642-4ff6-9d3c-f72c6eecda4d"}},{"cell_type":"code","metadata":{"_uuid":"97b2d85627fcde52a506dbdd55d4d6e4c87d3f08","cell_id":"f7d8171e-a537-4221-8741-87d737f36416"},"source":"train_df.dropna(subset=['comment'], inplace=True)","outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We notice that the dataset is indeed balanced","metadata":{"_uuid":"9d51637ee70dca7693737ad0da1dbb8c6ce9230b","cell_id":"511745eb-2605-4981-b12e-b9fef54c002f"}},{"cell_type":"code","metadata":{"_uuid":"addd77c640423d30fd146c8d3a012d3c14481e11","cell_id":"2f8bd579-2382-46a4-a936-4649a27aa245"},"source":"train_df['label'].value_counts()","outputs":[{"data":{"text/plain":"0    505405\n1    505368\nName: label, dtype: int64"},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"execution_count":null},{"cell_type":"markdown","source":"We split data into training and validation parts.","metadata":{"_uuid":"5b836574e5093c5eb2e9063fefe1c8d198dcba79","cell_id":"aa67bc49-4e4c-403e-9afd-c05e81be6d48"}},{"cell_type":"code","metadata":{"_uuid":"c200add4e1dcbaa75164bbcc73b9c12ecb863c96","cell_id":"ddc70633-472a-45d5-bf7a-754e01996ff2"},"source":"train_texts, valid_texts, y_train, y_valid = \\\n        train_test_split(train_df['comment'], train_df['label'], random_state=17)","outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Tasks:\n1. Analyze the dataset, make some plots. This [Kernel](https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-qiqc) might serve as an example\n2. Build a Tf-Idf + logistic regression pipeline to predict sarcasm (`label`) based on the text of a comment on Reddit (`comment`).\n3. Plot the words/bigrams which a most predictive of sarcasm (you can use [eli5](https://github.com/TeamHG-Memex/eli5) for that)\n4. (optionally) add subreddits as new features to improve model performance. Apply here the Bag of Words approach, i.e. treat each subreddit as a new feature.\n\n## Links:\n  - Machine learning library [Scikit-learn](https://scikit-learn.org/stable/index.html) (a.k.a. sklearn)\n  - Kernels on [logistic regression](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-2-classification) and its applications to [text classification](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-4-more-of-logit), also a [Kernel](https://www.kaggle.com/kashnitsky/topic-6-feature-engineering-and-feature-selection) on feature engineering and feature selection\n  - [Kaggle Kernel](https://www.kaggle.com/abhishek/approaching-almost-any-nlp-problem-on-kaggle) \"Approaching (Almost) Any NLP Problem on Kaggle\"\n  - [ELI5](https://github.com/TeamHG-Memex/eli5) to explain model predictions","metadata":{"_uuid":"7f0f47b98e49a185cd5cffe19fcbe28409bf00c0","cell_id":"6de75bd7-7f98-4f1c-b512-b7af81c947df"}}],"nbformat":4,"nbformat_minor":1,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"deepnote_notebook_id":"6b67c23e-4c6d-40de-a75c-3c97ab4f8276","deepnote_execution_queue":[]}}